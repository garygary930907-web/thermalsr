{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal-RGB Super-Resolution Data Pipeline\n",
    "## Part 0: Data Diagnosis & Synchronization\n",
    "\n",
    "This notebook will:\n",
    "1. Diagnose thermal data dropout issues\n",
    "2. Extract AVI video properties\n",
    "3. Parse time labels\n",
    "4. Synchronize all data sources\n",
    "5. Generate clean paired dataset for SR models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python numpy pandas matplotlib seaborn scipy tqdm Pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "from PIL import Image\n",
    "\n",
    "print(\"All dependencies imported successfully!\")\n",
    "\n",
    "# Set matplotlib style\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PATHS ====================\n",
    "DATA_DIR = Path('./data')\n",
    "THERMAL_DIR = DATA_DIR / 'thermal'\n",
    "CAMERA_DIR = DATA_DIR / 'camera'\n",
    "\n",
    "AVI_FILE = CAMERA_DIR / 'output.avi'\n",
    "LABELS_FILE = CAMERA_DIR / 'output.txt'\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = Path('./output')\n",
    "DIAGNOSIS_DIR = OUTPUT_DIR / 'diagnosis'\n",
    "SYNCHRONIZED_DIR = OUTPUT_DIR / 'synchronized'\n",
    "PAIRED_DIR = OUTPUT_DIR / 'paired_data'\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [DIAGNOSIS_DIR, SYNCHRONIZED_DIR, PAIRED_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==================== PARAMETERS ====================\n",
    "THERMAL_RES = (32, 24)  # Original thermal resolution\n",
    "TARGET_FPS = 8\n",
    "FRAME_INTERVAL = 1.0 / TARGET_FPS\n",
    "TIMESTAMP_TOLERANCE = FRAME_INTERVAL / 2\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Target FPS: {TARGET_FPS}\")\n",
    "print(f\"Timestamp tolerance: {TIMESTAMP_TOLERANCE:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Thermal Data with Diagnostic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalDiagnostics:\n",
    "    \"\"\"Load and diagnose thermal data.\"\"\"\n",
    "    \n",
    "    def __init__(self, thermal_dir: Path, resolution: Tuple[int, int] = (32, 24)):\n",
    "        self.thermal_dir = thermal_dir\n",
    "        self.resolution = resolution\n",
    "        self.data = []\n",
    "        self.diagnostics = {}\n",
    "    \n",
    "    def load_all_files(self):\n",
    "        \"\"\"Load all thermal TXT files.\"\"\"\n",
    "        log_files = sorted(self.thermal_dir.glob('log*.txt'))\n",
    "        print(f\"Found {len(log_files)} thermal log files\")\n",
    "        \n",
    "        total_frames = 0\n",
    "        file_stats = []\n",
    "        \n",
    "        for file_path in tqdm(log_files, desc=\"Loading thermal files\"):\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                file_frames = 0\n",
    "                for line_idx, line in enumerate(lines):\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        data_dict = json.loads(line)\n",
    "                        \n",
    "                        # Parse timestamp\n",
    "                        time_parts = data_dict.get('time', [])\n",
    "                        if len(time_parts) < 6:\n",
    "                            continue\n",
    "                        \n",
    "                        year, month, day, hour, minute, second = time_parts[:6]\n",
    "                        millisecond = time_parts[7] if len(time_parts) > 7 else 0\n",
    "                        \n",
    "                        try:\n",
    "                            timestamp = datetime(year, month, day, hour, minute, second, \n",
    "                                               millisecond * 1000)\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                        \n",
    "                        # Parse thermal image\n",
    "                        message = data_dict.get('message', [])\n",
    "                        if len(message) != self.resolution[0] * self.resolution[1]:\n",
    "                            continue\n",
    "                        \n",
    "                        thermal_image = np.array(message, dtype=np.uint8).reshape(\n",
    "                            self.resolution[1], self.resolution[0]\n",
    "                        )\n",
    "                        \n",
    "                        self.data.append({\n",
    "                            'timestamp': timestamp,\n",
    "                            'image': thermal_image,\n",
    "                            'file': file_path.name,\n",
    "                            'line': line_idx\n",
    "                        })\n",
    "                        \n",
    "                        file_frames += 1\n",
    "                    \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                \n",
    "                total_frames += file_frames\n",
    "                file_stats.append({\n",
    "                    'file': file_path.name,\n",
    "                    'frames': file_frames,\n",
    "                    'lines': len(lines)\n",
    "                })\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        self.data.sort(key=lambda x: x['timestamp'])\n",
    "        \n",
    "        self.diagnostics['total_frames'] = len(self.data)\n",
    "        self.diagnostics['file_stats'] = file_stats\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def analyze_timestamps(self):\n",
    "        \"\"\"Analyze timestamp distribution and dropout patterns.\"\"\"\n",
    "        if len(self.data) < 2:\n",
    "            print(\"Not enough data to analyze\")\n",
    "            return\n",
    "        \n",
    "        # Calculate time intervals between frames\n",
    "        timestamps = [d['timestamp'] for d in self.data]\n",
    "        intervals = []\n",
    "        \n",
    "        for i in range(1, len(timestamps)):\n",
    "            delta = (timestamps[i] - timestamps[i-1]).total_seconds()\n",
    "            intervals.append(delta)\n",
    "        \n",
    "        self.diagnostics['intervals'] = intervals\n",
    "        self.diagnostics['time_range'] = (timestamps[0], timestamps[-1])\n",
    "        self.diagnostics['duration'] = (timestamps[-1] - timestamps[0]).total_seconds()\n",
    "        \n",
    "        # Statistics\n",
    "        intervals = np.array(intervals)\n",
    "        self.diagnostics['interval_stats'] = {\n",
    "            'mean': float(np.mean(intervals)),\n",
    "            'std': float(np.std(intervals)),\n",
    "            'min': float(np.min(intervals)),\n",
    "            'max': float(np.max(intervals)),\n",
    "            'median': float(np.median(intervals))\n",
    "        }\n",
    "        \n",
    "        # Dropout detection\n",
    "        expected_interval = 1.0 / 8  # 8 fps ideal\n",
    "        threshold = expected_interval * 2  # 2x threshold\n",
    "        dropouts = np.where(intervals > threshold)[0]\n",
    "        \n",
    "        self.diagnostics['dropout_count'] = len(dropouts)\n",
    "        self.diagnostics['dropout_indices'] = dropouts.tolist()\n",
    "        \n",
    "        return self.diagnostics\n",
    "    \n",
    "    def print_diagnosis(self):\n",
    "        \"\"\"Print diagnostic report.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"THERMAL DATA DIAGNOSIS REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\n1. FILE STATISTICS:\")\n",
    "        file_df = pd.DataFrame(self.diagnostics['file_stats'])\n",
    "        print(file_df.to_string(index=False))\n",
    "        \n",
    "        print(f\"\\n2. TOTAL FRAMES LOADED: {self.diagnostics['total_frames']}\")\n",
    "        \n",
    "        if 'time_range' in self.diagnostics:\n",
    "            start, end = self.diagnostics['time_range']\n",
    "            print(f\"\\n3. TIME RANGE:\")\n",
    "            print(f\"   Start: {start}\")\n",
    "            print(f\"   End: {end}\")\n",
    "            print(f\"   Duration: {self.diagnostics['duration']:.2f}s\")\n",
    "            \n",
    "            stats = self.diagnostics['interval_stats']\n",
    "            print(f\"\\n4. FRAME INTERVAL STATISTICS (seconds):\")\n",
    "            print(f\"   Mean: {stats['mean']:.6f}s (ideal: 0.125s for 8fps)\")\n",
    "            print(f\"   Std: {stats['std']:.6f}s\")\n",
    "            print(f\"   Min: {stats['min']:.6f}s\")\n",
    "            print(f\"   Max: {stats['max']:.6f}s\")\n",
    "            print(f\"   Median: {stats['median']:.6f}s\")\n",
    "            \n",
    "            print(f\"\\n5. DROPOUT DETECTION:\")\n",
    "            print(f\"   Dropout count (>0.25s gap): {self.diagnostics['dropout_count']}\")\n",
    "            \n",
    "            if self.diagnostics['dropout_count'] > 0:\n",
    "                print(f\"   Dropout locations (frame indices):\")\n",
    "                dropouts = self.diagnostics['dropout_indices'][:10]  # Show first 10\n",
    "                for i, idx in enumerate(dropouts):\n",
    "                    gap = self.diagnostics['intervals'][idx]\n",
    "                    print(f\"     {i+1}. Frame {idx}->{idx+1}: {gap:.3f}s gap\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "\n# Load and diagnose thermal data\nthermal_diag = ThermalDiagnostics(THERMAL_DIR, THERMAL_RES)\nthermal_data = thermal_diag.load_all_files()\nthermal_diag.analyze_timestamps()\nthermal_diag.print_diagnosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load AVI Video & Extract Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoAnalyzer:\n",
    "    \"\"\"Analyze AVI video properties.\"\"\"\n",
    "    \n",
    "    def __init__(self, video_path: Path):\n",
    "        self.video_path = video_path\n",
    "        self.cap = None\n",
    "        self.fps = None\n",
    "        self.frame_count = None\n",
    "        self.width = None\n",
    "        self.height = None\n",
    "        self.duration = None\n",
    "    \n",
    "    def get_properties(self) -> bool:\n",
    "        \"\"\"Extract video properties without loading all frames.\"\"\"\n",
    "        if not self.video_path.exists():\n",
    "            print(f\"Error: Video file not found at {self.video_path}\")\n",
    "            return False\n",
    "        \n",
    "        self.cap = cv2.VideoCapture(str(self.video_path))\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {self.video_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Get properties\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.duration = self.frame_count / self.fps if self.fps > 0 else 0\n",
    "        \n",
    "        self.cap.release()\n",
    "        return True\n",
    "    \n",
    "    def print_info(self):\n",
    "        \"\"\"Print video information.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"AVI VIDEO PROPERTIES\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"File: {self.video_path.name}\")\n",
    "        print(f\"Resolution: {self.width} x {self.height}\")\n",
    "        print(f\"FPS: {self.fps}\")\n",
    "        print(f\"Total frames: {self.frame_count}\")\n",
    "        print(f\"Duration: {self.duration:.2f}s\")\n",
    "        print(\"=\"*60)\n",
    "\n\nvideo_analyzer = VideoAnalyzer(AVI_FILE)\nif video_analyzer.get_properties():\n",
    "    video_analyzer.print_info()\nelse:\n",
    "    print(\"Failed to analyze video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parse Time Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelParser:\n",
    "    \"\"\"Parse time labels from output.txt.\"\"\"\n",
    "    \n",
    "    def __init__(self, labels_file: Path):\n",
    "        self.labels_file = labels_file\n",
    "        self.events = []\n",
    "        self.video_start_time = None\n",
    "    \n",
    "    def parse_labels(self) -> bool:\n",
    "        \"\"\"Parse labels file.\"\"\"\n",
    "        if not self.labels_file.exists():\n",
    "            print(f\"Warning: Labels file not found at {self.labels_file}\")\n",
    "            return False\n",
    "        \n",
    "        with open(self.labels_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Parse lines\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Format: \"action_YYYY-MM-DD HH:MM:SS\"\n",
    "            parts = line.rsplit('_', 5)  # Split from right to get datetime\n",
    "            \n",
    "            if len(parts) >= 2:\n",
    "                action_part = '_'.join(parts[:-5]) if len(parts) > 6 else parts[0]\n",
    "                datetime_str = ' '.join(parts[-5:])\n",
    "                \n",
    "                try:\n",
    "                    # Parse datetime\n",
    "                    event_time = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')\n",
    "                    \n",
    "                    # Identify video start\n",
    "                    if 'video_start' in line or 'start' in line.lower():\n",
    "                        self.video_start_time = event_time\n",
    "                    \n",
    "                    self.events.append({\n",
    "                        'action': action_part,\n",
    "                        'timestamp': event_time,\n",
    "                        'raw': line\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not parse line '{line}': {e}\")\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        self.events.sort(key=lambda x: x['timestamp'])\n",
    "        return True\n",
    "    \n",
    "    def print_labels(self):\n",
    "        \"\"\"Print parsed labels.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PARSED TIME LABELS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if self.video_start_time:\n",
    "            print(f\"Video start time: {self.video_start_time}\")\n",
    "        \n",
    "        print(f\"\\nTotal events: {len(self.events)}\")\n",
    "        print(\"\\nEvents:\")\n",
    "        for i, event in enumerate(self.events):\n",
    "            print(f\"  {i+1}. {event['action']:15s} - {event['timestamp']}\")\n",
    "        \n",
    "        print(\"=\"*60)\n\n\nlabel_parser = LabelParser(LABELS_FILE)\nif label_parser.parse_labels():\n",
    "    label_parser.print_labels()\nelse:\n",
    "    print(\"No labels file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def establish_time_reference(thermal_data: List[Dict], \n",
    "                             video_analyzer: VideoAnalyzer,\n",
    "                             label_parser: LabelParser) -> Tuple[datetime, datetime, datetime]:\n",
    "    \"\"\"\n",
    "    Establish the time reference for synchronization.\n",
    "    \n",
    "    Returns:\n",
    "        (video_start, T_start, T_end) where:\n",
    "        - video_start: Reference time from labels or thermal data\n",
    "        - T_start: Start of overlapping window\n",
    "        - T_end: End of overlapping window\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get video start time from labels\n",
    "    video_start = label_parser.video_start_time\n",
    "    \n",
    "    if not video_start:\n",
    "        # Fallback: use first thermal frame\n",
    "        video_start = thermal_data[0]['timestamp']\n",
    "        print(f\"Warning: Using first thermal frame as reference: {video_start}\")\n",
    "    \n",
    "    # Get thermal time range\n",
    "    thermal_start = thermal_data[0]['timestamp']\n",
    "    thermal_end = thermal_data[-1]['timestamp']\n",
    "    \n",
    "    # Calculate RGB duration\n",
    "    rgb_duration = video_analyzer.duration\n",
    "    \n",
    "    # RGB time range (starting from video_start)\n",
    "    rgb_start = video_start\n",
    "    rgb_end = rgb_start + timedelta(seconds=rgb_duration)\n",
    "    \n",
    "    # Find overlapping window\n",
    "    T_start = max(thermal_start, rgb_start)\n",
    "    T_end = min(thermal_end, rgb_end)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TIME SYNCHRONIZATION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nVideo reference time: {video_start}\")\n",
    "    print(f\"\\nThermal time range:\")\n",
    "    print(f\"  Start: {thermal_start}\")\n",
    "    print(f\"  End: {thermal_end}\")\n",
    "    print(f\"  Duration: {(thermal_end - thermal_start).total_seconds():.2f}s\")\n",
    "    \n",
    "    print(f\"\\nRGB time range (calculated):\")\n",
    "    print(f\"  Start: {rgb_start}\")\n",
    "    print(f\"  End: {rgb_end}\")\n",
    "    print(f\"  Duration: {rgb_duration:.2f}s\")\n",
    "    \n",
    "    if T_start < T_end:\n",
    "        overlap_duration = (T_end - T_start).total_seconds()\n",
    "        print(f\"\\nOverlapping window:\")\n",
    "        print(f\"  Start: {T_start}\")\n",
    "        print(f\"  End: {T_end}\")\n",
    "        print(f\"  Duration: {overlap_duration:.2f}s\")\n",
    "        print(f\"  Expected frames @ 8fps: {int(overlap_duration * 8)}\")\n",
    "    else:\n",
    "        print(f\"\\nError: No overlapping window found!\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return video_start, T_start, T_end\n\n\nvideo_start, T_start, T_end = establish_time_reference(thermal_data, video_analyzer, label_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Target Timeline & Match Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_timeline(T_start: datetime, T_end: datetime, target_fps: float = 8) -> List[datetime]:\n",
    "    \"\"\"Create fixed target timeline.\"\"\"\n",
    "    timeline = []\n",
    "    current = T_start\n",
    "    interval = timedelta(seconds=1.0 / target_fps)\n",
    "    \n",
    "    while current <= T_end:\n",
    "        timeline.append(current)\n",
    "        current += interval\n",
    "    \n",
    "    return timeline\n\n\ndef find_nearest_thermal(target_time: datetime, thermal_data: List[Dict], \n",
    "                       tolerance: float = TIMESTAMP_TOLERANCE) -> Optional[Dict]:\n",
    "    \"\"\"Find nearest thermal frame within tolerance.\"\"\"\n",
    "    thermal_times = [d['timestamp'] for d in thermal_data]\n",
    "    \n",
    "    # Binary search\n",
    "    idx = np.searchsorted(thermal_times, target_time)\n",
    "    \n",
    "    best_idx = None\n",
    "    best_diff = float('inf')\n",
    "    \n",
    "    for cand_idx in [idx-1, idx]:\n",
    "        if 0 <= cand_idx < len(thermal_times):\n",
    "            diff = abs((thermal_times[cand_idx] - target_time).total_seconds())\n",
    "            if diff < tolerance and diff < best_diff:\n",
    "                best_idx = cand_idx\n",
    "                best_diff = diff\n",
    "    \n",
    "    return thermal_data[best_idx] if best_idx is not None else None\n\n\ndef find_nearest_rgb_frame(target_time: datetime, video_start: datetime,\n",
    "                         video_analyzer: VideoAnalyzer,\n",
    "                         tolerance: float = TIMESTAMP_TOLERANCE) -> Tuple[Optional[int], float]:\n",
    "    \"\"\"\n",
    "    Find nearest RGB frame index based on time offset.\n",
    "    \n",
    "    Returns:\n",
    "        (frame_index, time_offset_error)\n",
    "    \"\"\"\n",
    "    target_offset = (target_time - video_start).total_seconds()\n",
    "    \n",
    "    # Calculate frame index\n",
    "    frame_idx = int(target_offset * video_analyzer.fps)\n",
    "    \n",
    "    if 0 <= frame_idx < video_analyzer.frame_count:\n",
    "        actual_offset = frame_idx / video_analyzer.fps\n",
    "        error = abs(actual_offset - target_offset)\n",
    "        \n",
    "        if error < tolerance:\n",
    "            return frame_idx, error\n",
    "    \n",
    "    return None, float('inf')\n\n\n# Create target timeline\ntarget_timeline = create_target_timeline(T_start, T_end, TARGET_FPS)\nprint(f\"\\nTarget timeline created: {len(target_timeline)} frames @ {TARGET_FPS}fps\")\nprint(f\"Time range: {target_timeline[0]} to {target_timeline[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Synchronize & Create Paired Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize_thermal_rgb(target_timeline: List[datetime],\n",
    "                            thermal_data: List[Dict],\n",
    "                            video_start: datetime,\n",
    "                            video_analyzer: VideoAnalyzer,\n",
    "                            tolerance: float = TIMESTAMP_TOLERANCE) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Synchronize thermal and RGB frames.\n",
    "    \n",
    "    Returns:\n",
    "        List of synchronized pairs\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    skipped = {'no_thermal': 0, 'no_rgb': 0}\n",
    "    \n",
    "    for target_time in tqdm(target_timeline, desc=\"Synchronizing\"):\n",
    "        # Find thermal frame\n",
    "        thermal_frame = find_nearest_thermal(target_time, thermal_data, tolerance)\n",
    "        if thermal_frame is None:\n",
    "            skipped['no_thermal'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Find RGB frame\n",
    "        rgb_idx, error = find_nearest_rgb_frame(target_time, video_start, video_analyzer, tolerance)\n",
    "        if rgb_idx is None:\n",
    "            skipped['no_rgb'] += 1\n",
    "            continue\n",
    "        \n",
    "        pairs.append({\n",
    "            'timestamp': target_time,\n",
    "            'thermal': thermal_frame,\n",
    "            'rgb_frame_idx': rgb_idx,\n",
    "            'thermal_error': abs((thermal_frame['timestamp'] - target_time).total_seconds()),\n",
    "            'rgb_error': error\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nSynchronization Results:\")\n",
    "    print(f\"  Valid pairs: {len(pairs)}\")\n",
    "    print(f\"  Skipped (no thermal): {skipped['no_thermal']}\")\n",
    "    print(f\"  Skipped (no RGB): {skipped['no_rgb']}\")\n",
    "    print(f\"  Success rate: {len(pairs) / len(target_timeline) * 100:.1f}%\")\n",
    "    \n",
    "    return pairs\n\n\nsync_pairs = synchronize_thermal_rgb(target_timeline, thermal_data, video_start, video_analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract & Save RGB Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rgb_frames(sync_pairs: List[Dict],\n",
    "                       avi_path: Path,\n",
    "                       output_dir: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Extract RGB frames from AVI and save paired data.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(str(avi_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {avi_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Create subdirectories\n",
    "    thermal_dir = output_dir / 'thermal'\n",
    "    rgb_dir = output_dir / 'rgb'\n",
    "    thermal_dir.mkdir(parents=True, exist_ok=True)\n",
    "    rgb_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extract frames\n",
    "    frame_cache = {}\n",
    "    current_frame = 0\n",
    "    ret = True\n",
    "    \n",
    "    metadata_list = []\n",
    "    \n",
    "    for pair_idx, pair in enumerate(tqdm(sync_pairs, desc=\"Extracting frames\")):\n",
    "        target_frame_idx = pair['rgb_frame_idx']\n",
    "        \n",
    "        # Load frame if not cached\n",
    "        if target_frame_idx not in frame_cache:\n",
    "            # Seek to frame if needed\n",
    "            if target_frame_idx < current_frame:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame_idx)\n",
    "            \n",
    "            # Read until we get the target frame\n",
    "            while current_frame <= target_frame_idx and ret:\n",
    "                ret, frame = cap.read()\n",
    "                current_frame += 1\n",
    "            \n",
    "            if ret:\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_cache[target_frame_idx] = frame_rgb\n",
    "        \n",
    "        if target_frame_idx in frame_cache:\n",
    "            rgb_frame = frame_cache[target_frame_idx]\n",
    "            thermal_img = pair['thermal']['image']\n",
    "            \n",
    "            # Save thermal and RGB\n",
    "            pair_name = f\"pair_{pair_idx:05d}\"\n",
    "            \n",
    "            thermal_path = thermal_dir / f\"{pair_name}_thermal.npy\"\n",
    "            np.save(thermal_path, thermal_img.astype(np.uint8))\n",
    "            \n",
    "            rgb_path = rgb_dir / f\"{pair_name}_rgb.npy\"\n",
    "            np.save(rgb_path, rgb_frame.astype(np.uint8))\n",
    "            \n",
    "            metadata_list.append({\n",
    "                'pair_id': pair_name,\n",
    "                'timestamp': pair['timestamp'],\n",
    "                'rgb_frame_idx': pair['rgb_frame_idx'],\n",
    "                'thermal_file': pair['thermal']['file'],\n",
    "                'thermal_error_ms': pair['thermal_error'] * 1000,\n",
    "                'rgb_error_ms': pair['rgb_error'] * 1000\n",
    "            })\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_df = pd.DataFrame(metadata_list)\n",
    "    metadata_path = output_dir / 'metadata.csv'\n",
    "    metadata_df.to_csv(metadata_path, index=False)\n",
    "    \n",
    "    print(f\"\\nFrames extracted successfully!\")\n",
    "    print(f\"  Thermal frames saved to: {thermal_dir}\")\n",
    "    print(f\"  RGB frames saved to: {rgb_dir}\")\n",
    "    print(f\"  Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "    return True\n\n\nextract_rgb_frames(sync_pairs, AVI_FILE, SYNCHRONIZED_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize thermal timestamp distribution\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n# Plot 1: Timestamp intervals histogram\nintervals = thermal_diag.diagnostics.get('intervals', [])\nif intervals:\n",
    "    axes[0, 0].hist(intervals, bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(FRAME_INTERVAL, color='r', linestyle='--', label=f'Target: {FRAME_INTERVAL:.4f}s')\n",
    "    axes[0, 0].set_xlabel('Interval (seconds)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Thermal Frame Interval Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_xlim(0, 0.5)\n",
    "\n# Plot 2: Cumulative time\nif thermal_diag.diagnostics.get('intervals'):\n",
    "    cumulative = np.cumsum([0] + thermal_diag.diagnostics['intervals'])\n",
    "    axes[0, 1].plot(cumulative)\n",
    "    axes[0, 1].set_xlabel('Frame index')\n",
    "    axes[0, 1].set_ylabel('Cumulative time (seconds)')\n",
    "    axes[0, 1].set_title('Cumulative Time vs Frame Index')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n# Plot 3: Dropouts\ndropout_indices = thermal_diag.diagnostics.get('dropout_indices', [])\nif dropout_indices:\n",
    "    dropout_gaps = [thermal_diag.diagnostics['intervals'][i] for i in dropout_indices[:100]]\n",
    "    axes[1, 0].scatter(range(len(dropout_gaps)), dropout_gaps, alpha=0.6, s=50)\n",
    "    axes[1, 0].axhline(FRAME_INTERVAL * 2, color='r', linestyle='--', label='Dropout threshold')\n",
    "    axes[1, 0].set_xlabel('Dropout index')\n",
    "    axes[1, 0].set_ylabel('Gap duration (seconds)')\n",
    "    axes[1, 0].set_title('Frame Dropout Gaps (first 100)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n\n# Plot 4: Sync error\nif sync_pairs:\n",
    "    thermal_errors = [p['thermal_error'] * 1000 for p in sync_pairs]  # ms\n",
    "    rgb_errors = [p['rgb_error'] * 1000 for p in sync_pairs]  # ms\n",
    "    axes[1, 1].hist(thermal_errors, bins=30, alpha=0.5, label='Thermal error', edgecolor='black')\n",
    "    axes[1, 1].hist(rgb_errors, bins=30, alpha=0.5, label='RGB error', edgecolor='black')\n",
    "    axes[1, 1].set_xlabel('Time error (milliseconds)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Synchronization Error Distribution')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(DIAGNOSIS_DIR / 'thermal_diagnosis.png', dpi=100, bbox_inches='tight')\nplt.show()\n\nprint(f\"Diagnosis plot saved to {DIAGNOSIS_DIR / 'thermal_diagnosis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Sample Paired Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_paired_samples(sync_pairs: List[Dict],\n",
    "                             output_dir: Path,\n",
    "                             num_samples: int = 6):\n",
    "    \"\"\"\n",
    "    Visualize sample thermal-RGB pairs.\n",
    "    \"\"\"\n",
    "    thermal_dir = output_dir / 'thermal'\n",
    "    rgb_dir = output_dir / 'rgb'\n",
    "    \n",
    "    # Select samples uniformly distributed\n",
    "    if len(sync_pairs) > num_samples:\n",
    "        indices = np.linspace(0, len(sync_pairs) - 1, num_samples, dtype=int)\n",
    "    else:\n",
    "        indices = range(len(sync_pairs))\n",
    "    \n",
    "    # Create grid of visualizations\n",
    "    fig, axes = plt.subplots(len(indices), 2, figsize=(10, 4*len(indices)))\n",
    "    if len(indices) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for plot_idx, pair_idx in enumerate(indices):\n",
    "        pair = sync_pairs[pair_idx]\n",
    "        pair_name = f\"pair_{pair_idx:05d}\"\n",
    "        \n",
    "        # Load thermal\n",
    "        thermal_path = thermal_dir / f\"{pair_name}_thermal.npy\"\n",
    "        thermal_img = np.load(thermal_path)\n",
    "        \n",
    "        # Load RGB\n",
    "        rgb_path = rgb_dir / f\"{pair_name}_rgb.npy\"\n",
    "        rgb_img = np.load(rgb_path)\n",
    "        \n",
    "        # Plot thermal (upscaled for visibility)\n",
    "        thermal_upscaled = cv2.resize(thermal_img, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        axes[plot_idx][0].imshow(thermal_upscaled, cmap='hot')\n",
    "        axes[plot_idx][0].set_title(f'Thermal (32×24→256×256)\\nT_err: {pair[\"thermal_error\"]*1000:.1f}ms')\n",
    "        axes[plot_idx][0].axis('off')\n",
    "        \n",
    "        # Plot RGB (resized)\n",
    "        rgb_resized = cv2.resize(rgb_img, (256, 256))\n",
    "        axes[plot_idx][1].imshow(rgb_resized)\n",
    "        axes[plot_idx][1].set_title(f'RGB (640×320→256×256)\\nR_err: {pair[\"rgb_error\"]*1000:.1f}ms')\n",
    "        axes[plot_idx][1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAGNOSIS_DIR / 'sample_pairs.png', dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Sample visualization saved to {DIAGNOSIS_DIR / 'sample_pairs.png'}\")\n\n\nvisualize_paired_samples(sync_pairs, SYNCHRONIZED_DIR, num_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\nreport = f\"\"\"\n{'='*70}\nTHERMAL-RGB SYNCHRONIZATION PIPELINE - SUMMARY REPORT\n{'='*70}\n\n1. DATA LOADING\n   - Thermal frames loaded: {len(thermal_data)}\n   - Thermal data dropout count: {thermal_diag.diagnostics.get('dropout_count', 'N/A')}\n   - Video FPS: {video_analyzer.fps}\n   - Video total frames: {video_analyzer.frame_count}\n   - Video duration: {video_analyzer.duration:.2f}s\n\n2. TIME SYNCHRONIZATION\n   - Video start time: {video_start}\n   - Synchronization window: {T_start} to {T_end}\n   - Window duration: {(T_end - T_start).total_seconds():.2f}s\n   - Target FPS: {TARGET_FPS}\n   - Target timeline frames: {len(target_timeline)}\n\n3. FRAME MATCHING\n   - Successfully paired: {len(sync_pairs)}\n   - Success rate: {len(sync_pairs) / len(target_timeline) * 100:.1f}%\n   - Timestamp tolerance: ±{TIMESTAMP_TOLERANCE*1000:.1f}ms\n\n4. THERMAL FRAME INTERVALS\n   - Mean: {thermal_diag.diagnostics.get('interval_stats', {}).get('mean', 'N/A'):.6f}s\n   - Std Dev: {thermal_diag.diagnostics.get('interval_stats', {}).get('std', 'N/A'):.6f}s\n   - Min: {thermal_diag.diagnostics.get('interval_stats', {}).get('min', 'N/A'):.6f}s\n   - Max: {thermal_diag.diagnostics.get('interval_stats', {}).get('max', 'N/A'):.6f}s\n\n5. OUTPUT FILES\n   - Thermal frames: {SYNCHRONIZED_DIR / 'thermal'}\n   - RGB frames: {SYNCHRONIZED_DIR / 'rgb'}\n   - Metadata: {SYNCHRONIZED_DIR / 'metadata.csv'}\n   - Diagnostics: {DIAGNOSIS_DIR}\n\n6. NEXT STEPS\n   - Review diagnosis plots in {DIAGNOSIS_DIR}\n   - Check synchronized frame pairs in {SYNCHRONIZED_DIR}\n   - Use paired data for super-resolution training\n   - Available methods: RGB-as-GT, Self-Supervised, Hybrid\n\n{'='*70}\n\"\"\"\n\nprint(report)\n\n# Save report\nwith open(OUTPUT_DIR / 'REPORT.txt', 'w') as f:\n",
    "    f.write(report)\n\nprint(f\"\\nReport saved to {OUTPUT_DIR / 'REPORT.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Metadata Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display metadata\nmetadata_df = pd.read_csv(SYNCHRONIZED_DIR / 'metadata.csv')\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PAIRED DATASET METADATA\")\nprint(\"=\"*70)\nprint(f\"\\nTotal pairs: {len(metadata_df)}\")\nprint(f\"\\nMetadata Statistics:\")\nprint(metadata_df.describe())\n\nprint(f\"\\nFirst 10 pairs:\")\nprint(metadata_df.head(10).to_string(index=False))\n\nprint(f\"\\nSynchronization error statistics:\")\nprint(f\"  Thermal error - Mean: {metadata_df['thermal_error_ms'].mean():.2f}ms, \"\n      f\"Max: {metadata_df['thermal_error_ms'].max():.2f}ms\")\nprint(f\"  RGB error - Mean: {metadata_df['rgb_error_ms'].mean():.2f}ms, \"\n      f\"Max: {metadata_df['rgb_error_ms'].max():.2f}ms\")\n\nprint(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mim_name": "application/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}